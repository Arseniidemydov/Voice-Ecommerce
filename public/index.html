<!DOCTYPE html>
<html>
<head>
    <title>Voice Assistant</title>
    <style>
        body {
            background-color: #1a1a1a;
            color: white;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
        }

        .voice-button {
            width: 150px;  /* Reduced from 200px */
            height: 150px; /* Reduced from 200px */
            border-radius: 50%;
            background: #0066ff;
            border: none;
            cursor: pointer;
            position: relative;
            transition: all 0.3s ease;
            margin: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .voice-button::before {
            content: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="white" class="bi bi-mic" viewBox="0 0 16 16"><path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5"/><path d="M10 8a2 2 0 1 1-4 0V3a2 2 0 1 1 4 0zM8 0a3 3 0 0 0-3 3v5a3 3 0 0 0 6 0V3a3 3 0 0 0-3-3"/></svg>');
            font-size: 40px;
        }

        .voice-button.recording {
            animation: pulse 1.5s infinite;
            background: #ff0000;
        }

        .loading {
            border: 5px solid #f3f3f3;
            border-top: 5px solid #0066ff;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            display: none;
        }

        .loading.active {
            display: block;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        @keyframes spin {
            0% { transform: translate(-50%, -50%) rotate(0deg); }
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        #response {
            margin: 20px;
            padding: 30px 40px;  /* Increased padding */
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            max-width: 600px;
            width: calc(100% - 80px);  /* Adjusted width with margins */
            line-height: 1.6;  /* Added line spacing */
            font-size: 16px;   /* Added font size */
        }

        .status-text {
            text-align: center;
            margin-top: 20px;
            font-size: 14px;
            color: #888;
        }
    </style>
</head>
<body>
    <div class="voice-button" id="talkButton">
        <div class="loading" id="loadingIndicator"></div>
    </div>
    <div class="status-text" id="statusText">Click to talk to assistant</div>
    <div id="response"></div>
    
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <script>
        const ASSISTANT_ID = 'asst_CDvFyzLG7KL7aRuTymxyrY9W';
        const button = document.querySelector('.voice-button');
        const responseDiv = document.getElementById('response');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const statusText = document.getElementById('statusText');
        let mediaRecorder;
        let audioChunks = [];

        async function sendToOpenAI(blob) {
            try {
                loadingIndicator.classList.add('active');
                statusText.textContent = 'Processing...';

                const formData = new FormData();
                formData.append('file', blob, 'audio.webm');
                formData.append('model', 'whisper-1');

                const transcriptionResponse = await axios.post('/api/openai/audio/transcriptions', formData);
                const userText = transcriptionResponse.data.text;

                const threadResponse = await axios.post('/api/openai/threads');

                await axios.post(`/api/openai/threads/${threadResponse.data.id}/messages`, {
                    role: 'user',
                    content: userText
                });

                const runResponse = await axios.post(`/api/openai/threads/${threadResponse.data.id}/runs`, {
                    assistant_id: ASSISTANT_ID
                });

                let runStatus;
                do {
                    await new Promise(resolve => setTimeout(resolve, 1000));
                    const statusResponse = await axios.get(
                        `/api/openai/threads/${threadResponse.data.id}/runs/${runResponse.data.id}`
                    );
                    runStatus = statusResponse.data.status;
                } while (runStatus === 'in_progress');

                const messagesResponse = await axios.get(
                    `/api/openai/threads/${threadResponse.data.id}/messages`
                );
                const aiResponse = messagesResponse.data.data[0].content[0].text.value;

                const speechResponse = await axios.post('/api/openai/audio/speech', {
                    model: "tts-1",
                    input: aiResponse,
                    voice: "alloy"
                }, {
                    responseType: 'arraybuffer'
                });

                const audioBlob = new Blob([speechResponse.data], { type: 'audio/mpeg' });
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                await audio.play();

                // Just show the AI response without labels
                responseDiv.textContent = aiResponse;
                statusText.textContent = 'Click to start recording';

            } catch (error) {
                console.error('Error:', error.response?.data || error);
                responseDiv.textContent = 'Error processing request. Please try again.';
                statusText.textContent = 'Error occurred';
            } finally {
                loadingIndicator.classList.remove('active');
            }
        }

        button.onclick = async () => {
            try {
                if (!mediaRecorder) {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        await sendToOpenAI(audioBlob);
                        button.classList.remove('recording');
                        audioChunks = [];
                    };

                    button.classList.add('recording');
                    statusText.textContent = 'Recording... Click to stop';
                    mediaRecorder.start();
                } else {
                    mediaRecorder.stop();
                    const tracks = mediaRecorder.stream.getTracks();
                    tracks.forEach(track => track.stop());
                    mediaRecorder = null;
                    statusText.textContent = 'Processing...';
                }
            } catch (error) {
                console.error('Microphone error:', error);
                statusText.textContent = 'Error accessing microphone';
            }
        };
    </script>
</body>
</html>